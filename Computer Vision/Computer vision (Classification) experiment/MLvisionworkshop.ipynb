{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "55fc983e-8968-4833-93e7-299e3b4d3dfc",
   "metadata": {},
   "source": [
    "# üå≥ Tree Species Classification using Computer Vision üå≥"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7205a2e-6f03-4694-9a1f-8d9391be02f7",
   "metadata": {},
   "source": [
    "**Introduction:**\n",
    "\r\n",
    "Welcome to an exciting journey into the world of Computer Vision! In this GitHub project, we'll delve into the realm of Digital Image Processing to address a crucial ecological challenge: Tree Species Classification."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bccd70b-8044-4967-a4a6-08454937d5a1",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "**Overview:**\n",
    "\r\n",
    "Our project harnesses the power of Artificial Intelligence, specifically Computer Vision techniques, to tackle this challenge. We'll utilize Support Vector Machines (SVM) as our classifier and Convolutional Neural Networks (CNN) as feature extractors. By leveraging these cutting-edge technologies, we aim to build a robust model capable of accurately identifying tree species based on bark images."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0dc62b1-428c-4c54-ba0d-787a1748a52e",
   "metadata": {},
   "source": [
    "**Key Features:**\n",
    "\n",
    "üîç ***Image Analysis:***  Dive deep into the world of image analysis to extract meaningful features from bark images.\n",
    "\n",
    "üîß ***SVM Classifier:***  Employ Support Vector Machines to classify tree species with high accuracy and efficiency.\n",
    "\n",
    "üß† ***CNN Feature Extractor:***  Utilize Convolutional Neural Networks to automatically learn relevant features from raw image data.\n",
    "\n",
    "üìà ***Scalability:***  Develop a scalable solution that can handle large datasets of tree bark images.\n",
    "\n",
    "üå± ***Ecological Impact:***  Contribute to environmental conservation efforts by facilitating accurate tree species identification.tion."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dff9886-0870-4283-8ba2-2e2cd041afa2",
   "metadata": {},
   "source": [
    "<font color='red'>\n",
    "Ready to Get Started?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e2842a6-f568-482e-889a-7f74d6b851e5",
   "metadata": {},
   "source": [
    "## Import necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bb97301a-e40a-471e-ada4-a159075ad820",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\gokul\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from sklearn.svm import SVC  # Support Vector Machines\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report  # For accuracy\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential #For CNN\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten  #for CNN\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from sklearn.model_selection import train_test_split #traning and testing seperation\n",
    "import cv2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b163e8db-ffda-440d-b372-5e41893507c3",
   "metadata": {},
   "source": [
    "<font color='darkblue'>\n",
    "\n",
    "### **Detailed Overview of Imported Libraries:**\r",
    ">\n",
    "\n",
    "\r\n",
    "1. **os**\r\n",
    "   - *Purpose*: File and Directory Operations\r\n",
    "   - *Description*: Facilitates seamless interaction with the file system, enabling efficient file and directory manipulati\n",
    "on.\r\n",
    "\r\n",
    "2. **SVC from sklearn.svm**\r\n",
    "   - *Purpose*: Support Vector Machines (SVMs)\r\n",
    "   - *Description*: Empowers the implementation of SVM-based classification algorithms, renowned for their effectiveness in handling complex datasets.\r\n",
    "\r\n",
    "3. **accuracy_score, precision_score, recall_score, f1_score, classification_report from sklearn.metrics**\r\n",
    "   - *Purpose*: Evaluation of Classification Performance\r\n",
    "   - *Description*: Offers a comprehensive suite of metrics for assessing the performance of classification models, ensuring robust evaluation and validation.\r\n",
    "\r\n",
    "4. **numpy**\r\n",
    "   - *Purpose*: Numerical Computations\r\n",
    "   - *Description*: Provides essential functionalities for numerical operations, array manipulation, and mathematical computations, serving as the backbone for data manipulation in Python.\r\n",
    "\r\n",
    "5. **Sequential, Conv2D, MaxPooling2D, Flatten from tensorflow.keras.layers**\r\n",
    "   - *Purpose*: Defining Convolutional Neural Networks (CNN) Architecture\r\n",
    "   - *Description*: Enables the construction of CNN architectures by providing essential layers for convolution, pooling, and flattening, facilitating effective feature extraction from images.\r\n",
    "\r\n",
    "6. **img_to_array from tensorflow.keras.preprocessing.image**\r\n",
    "   - *Purpose*: Converting Images to Arrays\r\n",
    "   - *Description*: Transforms image data into numerical arrays, a prerequisite for processing images within neural network frameworks, ensuring seamless integration of image data into machine learning pipelines.\r\n",
    "\r\n",
    "7. **train_test_split from sklearn.model_selection**\r\n",
    "   - *Purpose*: Splitting Data into Training and Testing Sets\r\n",
    "   - *Description*: Facilitates the partitioning of datasets into training and testing subsets, crucial for model training, validation, and evaluation, ensuring robustness and generalization.\r\n",
    "\r\n",
    "8. **cv2**\r\n",
    "   - *Purpose*: OpenCV (Open Source Computer Vision Library)\r\n",
    "   - *Description*: Provides a rich set of functionalities for computer vision tasks, including image processing, object detection, and feature extraction, empowering the development of sophisticated computer vision applications.\r\n",
    "on."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1134364b-d685-4a5b-b839-de1d90bfc85d",
   "metadata": {},
   "source": [
    "## Define Function to Load and Extract Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1a97e71b-477d-444b-9375-3bd933322d57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to load and extract features from images\n",
    "def load_and_extract_features(data_path):\n",
    "    features_cnn = []\n",
    "    labels = []\n",
    "\n",
    "    categories = os.listdir(data_path)\n",
    "\n",
    "    for category in categories:\n",
    "        category_path = os.path.join(data_path, category)\n",
    "        for img_name in os.listdir(category_path):\n",
    "            img_path = os.path.join(category_path, img_name)\n",
    "            img = cv2.imread(img_path)\n",
    "            if img is None:\n",
    "                print(f\"Failed to load image: {img_path}\")\n",
    "                continue\n",
    "            print(\"Loaded image shape:\", img.shape)\n",
    "            img = cv2.resize(img, (90, 90))\n",
    "            img_cnn = img_to_array(img)\n",
    "            features_cnn.append(img_cnn)\n",
    "            labels.append(category)\n",
    "\n",
    "    features_cnn = np.array(features_cnn)\n",
    "    labels = np.array(labels)\n",
    "\n",
    "    return features_cnn, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eea8630-297a-4634-8c94-881ca9a213ee",
   "metadata": {},
   "source": [
    "<font color='darkblue'>\n",
    "\n",
    "#### Detailed overview of load and extract features\n",
    "\n",
    "\n",
    "\n",
    "The \"load_and_extract_features\" function loads images from the specified path and extracts features using Convolutional Neural Networks (CNN). After this the fucntion returns the extracted features along with the corresponding labels\n",
    "\n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e46514aa-ff12-4ec2-9a88-0b60bc761bed",
   "metadata": {},
   "source": [
    "### Defining CNN model for feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "89fbc866-48d3-4fd9-a8e7-bd752e43728b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a CNN model for feature extraction\n",
    "def create_cnn_model():\n",
    "    model_cnn = Sequential()\n",
    "    model_cnn.add(Conv2D(32, (3, 3), activation='relu', input_shape=(90, 90, 3)))\n",
    "    model_cnn.add(MaxPooling2D((2, 2)))\n",
    "    model_cnn.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "    model_cnn.add(MaxPooling2D((2, 2)))\n",
    "    model_cnn.add(Flatten())\n",
    "\n",
    "    return model_cnn\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cca9b03-3313-4f6f-8e99-9de6fceb0131",
   "metadata": {},
   "source": [
    "<font color='darkblue'>\n",
    "\n",
    "#### **Detailed Overview of CNN Model**\n",
    ">\n",
    "\n",
    "\n",
    "\n",
    "</font>\n",
    "\n",
    "<font color='purple'>\n",
    "\n",
    "***def create_cnn_model()***\n",
    "- **Description**: Defines a function named 'create_cnn_model' which will return a CNN model.\n",
    "\n",
    "</font>\n",
    "\n",
    "<font color='green'>\n",
    "\n",
    "***model_cnn = Sequential ()***\n",
    "- **Description**: Initializes a Sequential model. Sequential is a Keras API that allows creating models layer-by-layer in a linear fashion.\n",
    "\n",
    "</font>\n",
    "\n",
    "<font color='blue'>\n",
    "\n",
    "***model_cnn.add(Conv2D(32, (3, 3), activation='relu', input_shape=(90, 90, 3)))*** \n",
    "- **Description**: Adds a 2D convolutional layer (Conv2D) with 32 filters, each with a size of 3x3, and uses ReLU (Rectified Linear Activation) as the activation function. input_shape=(90, 90, 3) specifies the shape of input data, which is an image with dimensions 90x90 pixels and 3 color channels (RGB).\n",
    "\n",
    "</font>\n",
    "\n",
    "<font color='orange'>\n",
    "\n",
    "***model_cnn.add(MaxPooling2D((2, 2)))*** \n",
    "- **Description**: Adds a max pooling layer (MaxPooling2D) with a pool size of 2x2. Max pooling reduces the spatial dimensions of the input volume.\n",
    "\n",
    "</font>\n",
    "\n",
    "<font color='red'>\n",
    "\n",
    "***model_cnn.add(Conv2D(64, (3, 3), activation='relu'))***\n",
    "- **Description**: Adds another 2D convolutional layer with 64 filters, each with a size of 3x3, and again uses ReLU as the activation function.\n",
    "\n",
    "</font>\n",
    "\n",
    "<font color='brown'>\n",
    "\n",
    "***model_cnn.add(MaxPooling2D((2, 2)))*** \n",
    "- **Description**: Adds another max pooling layer.\n",
    "\n",
    "</font>\n",
    "\n",
    "<font color='teal'>\n",
    "\n",
    "***model_cnn.add(Flatten())***\n",
    "- **Description**: Adds a Flatten layer. This layer flattens the multi-dimensional output of the previous layer into a one-dimensional vector, which can be fed into a fully connected layer.\n",
    "\n",
    "</font>\n",
    "\n",
    "<font color='maroon'>\n",
    "\n",
    "***return model_cnn*** \n",
    "- **Description**: Returns the created CNN model.\n",
    "\n",
    "</font>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bc2172a-b6de-4627-8f39-a9c04d4503cb",
   "metadata": {},
   "source": [
    "### Defining Classiying function, model traning, testing, accuracy reports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "309dedd2-6aed-45b9-93f6-811e1cee3353",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Function to classify images using SVM\n",
    "def classify_images(data_path, train_size=0.8, test_size=0.2):\n",
    "    # Load and extract features from images\n",
    "    features_cnn, labels = load_and_extract_features(data_path)\n",
    "\n",
    "    # Create CNN model for feature extraction\n",
    "    model_cnn = create_cnn_model()\n",
    "\n",
    "    # Extract CNN features for all images\n",
    "    features_cnn = model_cnn.predict(features_cnn)\n",
    "\n",
    "    # Create SVM classifier\n",
    "    clf = SVC(kernel='rbf', C=1.0)\n",
    "\n",
    "    # Split the data into training and testing sets\n",
    "    x_train, x_test, y_train, y_test = train_test_split(features_cnn, labels, test_size=test_size, train_size=train_size, random_state=42)\n",
    "\n",
    "    # Train the SVM classifier\n",
    "    clf.fit(x_train, y_train)\n",
    "\n",
    "    # Predict labels for test data\n",
    "    y_pred = clf.predict(x_test)\n",
    "\n",
    "    # Calculate performance metrics\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred, average='weighted')\n",
    "    recall = recall_score(y_test, y_pred, average='weighted')\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "    # Print the performance metrics\n",
    "    print(f\"Accuracy: {accuracy}\")\n",
    "    print(f\"Precision: {precision}\")\n",
    "    print(f\"Recall: {recall}\")\n",
    "    print(f\"F1-score: {f1}\")\n",
    "\n",
    "    # Print classification report\n",
    "    print(classification_report(y_test, y_pred))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5f458dc-0dc2-4e70-a06e-57209fc84c8e",
   "metadata": {},
   "source": [
    "\n",
    "<font color='darkblue'>\n",
    "\n",
    "### **Detailed overview of Classify function:**\n",
    "\n",
    ">\r\n",
    "\r\n",
    "1. **Load and Extract Features from Images**\r\n",
    "    - The function `load_and_extract_features(data_path)` presumably loads images from a specified data_path and extracts features using a CNN model.\r\n",
    "\r\n",
    "2. **Create CNN Model for Feature Extraction**\r\n",
    "    - 'create_cnn_model()' is a function that creates a CNN model for feature extraction. This CNN model is then used to extract features from the images.\r\n",
    "\r\n",
    "3. **Extract CNN Features for All Images**\r\n",
    "    - Once the CNN model is created, it's used to extract features from all images loaded in the previous step.\r\n",
    "\r\n",
    "4. **Create SVM Classifier**\r\n",
    "    - An SVM classifier (clf) with a radial basis function kernel (kernel='rbf') and regularization parameter C=1.0 is created.\r\n",
    "\r\n",
    "5. **Split the Data into Training and Testing Sets**\r\n",
    "    - The extracted features and corresponding labels are split into training and testing sets using 'train_test_split'.\r\n",
    "\r\n",
    "6. **Train the SVM Classifier**\r\n",
    "    - The SVM classifier is trained using the training data.\r\n",
    "\r\n",
    "7. **Predict Labels for Test Data**\r\n",
    "    - The trained SVM classifier is then used to predict labels for the test data.\r\n",
    "\r\n",
    "8. **Calculate Performance Metrics**\r\n",
    "    - Performance metrics such as accuracy, precision, recall, and F1-score are calculated using 'accuracy_score', 'precision_score', 'recall_score', and 'f1_score', respectively.\r\n",
    "\r\n",
    "9. **Print the Performance Metrics**\r\n",
    "    - Display the calculated performance metrics for evaluation.\r\n",
    "\r\n",
    "10. **Print Classification Report**\r\n",
    "    - Print a comprehensive classification report providing insights into the classification performance.\r\n",
    "\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "180d381a-5188-4fdc-922f-cb44c1e306b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded image shape: (6960, 1808, 3)\n",
      "Loaded image shape: (6960, 1818, 3)\n",
      "Loaded image shape: (6960, 1707, 3)\n",
      "Loaded image shape: (6960, 1722, 3)\n",
      "Loaded image shape: (6960, 1588, 3)\n",
      "Loaded image shape: (6960, 1582, 3)\n",
      "Loaded image shape: (6960, 1457, 3)\n",
      "Loaded image shape: (6960, 1718, 3)\n",
      "Loaded image shape: (6960, 1718, 3)\n",
      "Loaded image shape: (6960, 1613, 3)\n",
      "Loaded image shape: (6960, 1677, 3)\n",
      "Loaded image shape: (6960, 1717, 3)\n",
      "Loaded image shape: (6960, 1898, 3)\n",
      "Loaded image shape: (6960, 1748, 3)\n",
      "Loaded image shape: (6960, 1748, 3)\n",
      "Loaded image shape: (6960, 1757, 3)\n",
      "Loaded image shape: (6960, 1888, 3)\n",
      "Loaded image shape: (6960, 1803, 3)\n",
      "Loaded image shape: (6960, 1758, 3)\n",
      "Loaded image shape: (6960, 1893, 3)\n",
      "Loaded image shape: (6960, 1979, 3)\n",
      "Loaded image shape: (6960, 1898, 3)\n",
      "Loaded image shape: (6960, 1988, 3)\n",
      "Loaded image shape: (6960, 2053, 3)\n",
      "Loaded image shape: (6960, 2199, 3)\n",
      "Loaded image shape: (6960, 2400, 3)\n",
      "Loaded image shape: (6960, 2485, 3)\n",
      "Loaded image shape: (6960, 2520, 3)\n",
      "Loaded image shape: (6960, 2721, 3)\n",
      "Loaded image shape: (6960, 2771, 3)\n",
      "Loaded image shape: (6880, 1986, 3)\n",
      "Loaded image shape: (6960, 1702, 3)\n",
      "Loaded image shape: (6960, 1768, 3)\n",
      "Loaded image shape: (6960, 2440, 3)\n",
      "Loaded image shape: (6960, 2640, 3)\n",
      "Loaded image shape: (6960, 2770, 3)\n",
      "Loaded image shape: (6960, 2635, 3)\n",
      "Loaded image shape: (6960, 2711, 3)\n",
      "Loaded image shape: (6960, 2671, 3)\n",
      "Loaded image shape: (6960, 2370, 3)\n",
      "Loaded image shape: (6960, 1969, 3)\n",
      "Loaded image shape: (6960, 1988, 3)\n",
      "Loaded image shape: (6960, 1798, 3)\n",
      "Loaded image shape: (6960, 1617, 3)\n",
      "Loaded image shape: (6960, 1768, 3)\n",
      "Loaded image shape: (6960, 1918, 3)\n",
      "Loaded image shape: (6960, 1943, 3)\n",
      "Loaded image shape: (6960, 1849, 3)\n",
      "Loaded image shape: (6960, 1848, 3)\n",
      "Loaded image shape: (6960, 1883, 3)\n",
      "Loaded image shape: (6960, 3463, 3)\n",
      "Loaded image shape: (6960, 3142, 3)\n",
      "Loaded image shape: (6960, 2941, 3)\n",
      "Loaded image shape: (6960, 3117, 3)\n",
      "Loaded image shape: (6960, 3132, 3)\n",
      "Loaded image shape: (6960, 2911, 3)\n",
      "Loaded image shape: (6960, 3066, 3)\n",
      "Loaded image shape: (6960, 3041, 3)\n",
      "Loaded image shape: (6960, 2891, 3)\n",
      "Loaded image shape: (6960, 2891, 3)\n",
      "Loaded image shape: (6960, 3082, 3)\n",
      "Loaded image shape: (6960, 3327, 3)\n",
      "Loaded image shape: (6960, 3292, 3)\n",
      "Loaded image shape: (6960, 3804, 3)\n",
      "Loaded image shape: (6960, 3302, 3)\n",
      "Loaded image shape: (6960, 3904, 3)\n",
      "Loaded image shape: (6960, 3523, 3)\n",
      "Loaded image shape: (6960, 3904, 3)\n",
      "Loaded image shape: (6960, 3358, 3)\n",
      "Loaded image shape: (6960, 3177, 3)\n",
      "Loaded image shape: (6960, 2670, 3)\n",
      "Loaded image shape: (6960, 3287, 3)\n",
      "Loaded image shape: (6959, 3556, 3)\n",
      "Loaded image shape: (6960, 2997, 3)\n",
      "Loaded image shape: (6960, 2476, 3)\n",
      "Loaded image shape: (6960, 3335, 3)\n",
      "Loaded image shape: (6960, 3206, 3)\n",
      "Loaded image shape: (6960, 2909, 3)\n",
      "Loaded image shape: (6960, 2934, 3)\n",
      "Loaded image shape: (6960, 3600, 3)\n",
      "Loaded image shape: (6960, 2388, 3)\n",
      "Loaded image shape: (6960, 2838, 3)\n",
      "Loaded image shape: (6927, 3343, 3)\n",
      "Loaded image shape: (6960, 3222, 3)\n",
      "Loaded image shape: (6960, 2653, 3)\n",
      "Loaded image shape: (6911, 3096, 3)\n",
      "Loaded image shape: (6960, 3471, 3)\n",
      "Loaded image shape: (6960, 2992, 3)\n",
      "Loaded image shape: (6960, 2388, 3)\n",
      "Loaded image shape: (6926, 3047, 3)\n",
      "WARNING:tensorflow:From C:\\Users\\gokul\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\gokul\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\src\\layers\\pooling\\max_pooling2d.py:161: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "3/3 [==============================] - 0s 28ms/step\n",
      "Accuracy: 0.8333333333333334\n",
      "Precision: 0.8595679012345678\n",
      "Recall: 0.8333333333333334\n",
      "F1-score: 0.8326797385620915\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "  Betula Pendula       0.78      0.88      0.82         8\n",
      "Carpinus Betulus       1.00      0.75      0.86         4\n",
      "   Larix Decidua       1.00      0.67      0.80         3\n",
      "          Spruce       0.75      1.00      0.86         3\n",
      "\n",
      "        accuracy                           0.83        18\n",
      "       macro avg       0.88      0.82      0.83        18\n",
      "    weighted avg       0.86      0.83      0.83        18\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data_path = \"D:/MLsample_bark\"  # Specify the path to your image dataset folder\n",
    "classify_images(data_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca8f54b3-018d-4f40-8475-754df1f322b0",
   "metadata": {},
   "source": [
    "## Meet the Developers\n",
    "\n",
    "- **Gokul Kottilapurath Surendran**  \n",
    "  - *Role:* PhD Scholar  \n",
    "  - *Email:* [ksg@fld.czu.cz](mailto:ksg@fld.czu.cz)  \n",
    "  - *GitHub:* [Gokul-tcr](https://github.com/Gokultcr)\n",
    "\n",
    "- **Dr. Martin Mokros**  \n",
    "  - *Role:* Supervisor  \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
